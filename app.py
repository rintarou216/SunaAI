import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as transforms
from torchvision import models, datasets
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from datetime import datetime
import os
import zipfile

# ----- è¨­å®š -----
class_names = ['glow', 'non_glow']
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
BATCH_SIZE = 4
EPOCHS = 3

# ----- ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ -----
@st.cache_resource
def load_model():
    model = models.resnet18(pretrained=False)
    model.fc = nn.Linear(model.fc.in_features, 2)
    model.load_state_dict(torch.load("glow_model.pth", map_location=device))
    model.eval()
    return model.to(device)

model = load_model()

# ----- ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ -----
st.sidebar.title("ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
mode = st.sidebar.radio("å‡¦ç†ã‚’é¸ã‚“ã§ãã ã•ã„", ("å˜ä½“ç”»åƒã§åˆ¤å®š", "ZIPç”»åƒã‚’ä¸€æ‹¬åˆ¤å®š"))

# ================================
# ãƒ¢ãƒ¼ãƒ‰â‘ ï¼šå˜ä½“ç”»åƒã§åˆ¤å®šï¼‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
# ================================
if mode == "å˜ä½“ç”»åƒã§åˆ¤å®š":
    st.title("Bearing Glow åˆ¤å®šï¼†ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆå˜ä½“ï¼‰")
    uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])

    if uploaded_file:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_column_width=True)

        input_tensor = transform(image).unsqueeze(0).to(device)
        with torch.no_grad():
            output = model(input_tensor)
            _, predicted = torch.max(output, 1)
            result = class_names[predicted.item()]

        st.subheader(f"åˆ¤å®šçµæœ: :blue[{result}]")

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½
        col1, col2 = st.columns(2)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{result}_{timestamp}.jpg"

        if col1.button("â—¯ åˆã£ã¦ãŸï¼ˆæ­£è§£ï¼‰"):
            st.success("æ­£è§£ã¨ã—ã¦è¨˜éŒ²ã•ã‚Œã¾ã—ãŸï¼")

        if col2.button("Ã— é•ã£ã¦ãŸï¼ˆèª¤åˆ¤å®šï¼‰"):
            corrected_label = "non_glow" if result == "glow" else "glow"
            save_dir = os.path.join("corrected_data", corrected_label)
            os.makedirs(save_dir, exist_ok=True)
            image.save(os.path.join(save_dir, filename))
            st.warning(f"èª¤åˆ¤å®šç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")

# ================================
# ãƒ¢ãƒ¼ãƒ‰â‘¡ï¼šZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬åˆ¤å®šï¼†ä»•åˆ†ã‘
# ================================
elif mode == "ZIPç”»åƒã‚’ä¸€æ‹¬åˆ¤å®š":
    st.title("Bearing Glow åˆ¤å®šï¼†ä»•åˆ†ã‘ï¼ˆZIPä¸€æ‹¬ï¼‰")
    uploaded_file = st.file_uploader("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["zip"])

    if uploaded_file:
        with zipfile.ZipFile(uploaded_file, "r") as zip_ref:
            zip_ref.extractall("uploaded_images")

        image_files = [f for f in os.listdir("uploaded_images") if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        if not image_files:
            st.error("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã«ç”»åƒãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            st.success(f"{len(image_files)} æšã®ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼")

            result_dir = "sorted_images"
            os.makedirs(os.path.join(result_dir, "glow"), exist_ok=True)
            os.makedirs(os.path.join(result_dir, "non_glow"), exist_ok=True)

            for image_file in image_files:
                image_path = os.path.join("uploaded_images", image_file)
                image = Image.open(image_path).convert("RGB")
                input_tensor = transform(image).unsqueeze(0).to(device)

                with torch.no_grad():
                    output = model(input_tensor)
                    _, predicted = torch.max(output, 1)
                    result = class_names[predicted.item()]

                save_path = os.path.join(result_dir, result, image_file)
                image.save(save_path)
                st.image(image, caption=f"{image_file} - åˆ¤å®šçµæœ: {result}", use_column_width=True)

            st.success("ã™ã¹ã¦ã®ç”»åƒãŒä»•åˆ†ã‘ã•ã‚Œã¾ã—ãŸï¼")

# ================================
# å…±é€šï¼šå†å­¦ç¿’æ©Ÿèƒ½
# ================================
st.markdown("---")
if st.button("ğŸ” ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’"):

    data_dir = "corrected_data"
    if not os.path.exists(data_dir):
        st.error("å†å­¦ç¿’ç”¨ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("å†å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")

        dataset = datasets.ImageFolder(data_dir, transform=transform)
        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

        finetune_model = models.resnet18(pretrained=False)
        finetune_model.fc = nn.Linear(finetune_model.fc.in_features, 2)
        finetune_model.load_state_dict(torch.load("glow_model.pth", map_location=device))
        finetune_model = finetune_model.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(finetune_model.parameters(), lr=1e-4)

        finetune_model.train()
        for epoch in range(EPOCHS):
            running_loss = 0.0
            for inputs, labels in dataloader:
                inputs, labels = inputs.to(device), labels.to(device)
                optimizer.zero_grad()
                outputs = finetune_model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
            st.write(f"Epoch {epoch+1}/{EPOCHS} - Loss: {running_loss:.4f}")

        torch.save(finetune_model.state_dict(), "glow_model.pth")
        st.success("å†å­¦ç¿’å®Œäº†ï¼ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ âœ…")
